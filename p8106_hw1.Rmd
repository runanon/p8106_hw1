---
title: "P8106 HW 1"
output: github_document
---

```{r, include=FALSE}
library(tidyverse)
library(ISLR)
library(glmnet)
library(caret)
library(corrplot)
library(plotmo)
```

```{r, include=FALSE}
train = read.csv("./data/solubility_train.csv")
test= read.csv("./data/solubility_test.csv")
```

### (a) Fit a linear model using least squares on the training data and calculate the mean square error using the test data.

Fit a linear model
```{r}
# Fit model using train data
fit1 = lm(Solubility ~ ., data = train)
summary(fit1)
```

MSE
```{r}
# MSE using test data
pred_va <- predict(fit1, test)
# validation set error
mean((pred_va-test$Solubility)^2)
```

### (b) Fit a ridge regression model on the training data, with λ chosen by cross-validation. Report the test error.

Fit a ridge regression model
```{r}
train <- na.omit(train)

x_train <- model.matrix(Solubility~., train)[,-1]
y_train <- train$Solubility

x_test <- model.matrix(Solubility~., test)[,-1]
y_test <- test$Solubility
```

```{r}
# fit the ridge regression (alpha = 0) with a sequence of lambdas
ridge.mod <- glmnet(x_train, y_train, alpha=0, lambda = exp(seq(-1, 10, length=100)))
```

```{r}
set.seed(1)
cv.ridge <- cv.glmnet(x_train, y_train, 
                      alpha = 0, 
                      lambda = exp(seq(-1, 10, length=100)), 
                      type.measure = "mse")

plot(cv.ridge)
```

```{r}
best.lambda <- cv.ridge$lambda.min
best.lambda
predict(ridge.mod, s = best.lambda, type="coefficients")
```

MSE
```{r}
ridge.pred = predict(ridge.mod, s = best.lambda, newx = x_test)
mean((ridge.pred - y_test)^2)
```


### (c) Fit a lasso model on the training data, with λ chosen by cross-validation. Report the test error, along with the number of non-zero coefficient estimates.

Fit a lasso model

```{r}
lasso.mod <- glmnet(x_train, y_train, alpha=1, lambda = exp(seq(-1, 5, length=100)))
```

```{r}
set.seed(1)
cv.lasso <- cv.glmnet(x_train, y_train, alpha = 1, lambda = exp(seq(-1, 5, length=100)))
best.lambda <- cv.lasso$lambda.min
```

```{r}
plot(cv.lasso)
```

The number of non-zero coefficient estimates

```{r}
lasso_coef = predict(cv.lasso, s="lambda.min", type="coefficients")
lasso_coef
lasso_coef[lasso_coef != 0] # Display only non-zero coefficients
```

The number of non-zero coefficient is 9.

MSE

```{r}
lasso.pred = predict(lasso.mod, s=best.lambda, newx = x_test)
mean((lasso.pred - y_test)^2)
```

#### (d) Fit a PCR model on the training data, with M chosen by cross-validation. Report the test error, along with the value of M selected by cross-validation.





#### (e) Briefly discuss the results obtained in (a)∼(d).